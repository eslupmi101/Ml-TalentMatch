{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "39d45c40-0ed9-466a-a300-49e3a2a0022f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import List\n",
    "\n",
    "from langchain_core.output_parsers import JsonOutputParser\n",
    "from langchain_core.pydantic_v1 import BaseModel, Field\n",
    "\n",
    "\n",
    "from langchain.prompts import load_prompt\n",
    "from langchain.prompts import PromptTemplate\n",
    "\n",
    "from getpass import getpass\n",
    "\n",
    "from langchain_openai import ChatOpenAI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "5114bee3-6bd3-4472-8a07-ea85aab0e37d",
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'docx2txt'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[3], line 3\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mos\u001b[39;00m\n\u001b[1;32m      2\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mrequests\u001b[39;00m\n\u001b[0;32m----> 3\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mdocx2txt\u001b[39;00m\n\u001b[1;32m      4\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mdocx\u001b[39;00m\n\u001b[1;32m      5\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mPyPDF2\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m PdfReader\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'docx2txt'"
     ]
    }
   ],
   "source": [
    "# import os\n",
    "# import requests\n",
    "# import docx2txt\n",
    "# import docx\n",
    "# from PyPDF2 import PdfReader\n",
    "\n",
    "# class FileConverterService:\n",
    "#     def __init__(self):\n",
    "#         self.file_identifier = None\n",
    "#         self.file_path = None\n",
    "\n",
    "#     def execute(self, file_identifier):\n",
    "#         self.file_identifier = file_identifier\n",
    "#         self.file_path = self._get_file_path()\n",
    "\n",
    "#         if self.file_path:\n",
    "#             return self.convert_to_text()\n",
    "#         else:\n",
    "#             return \"File not found\"\n",
    "\n",
    "#     def convert_to_text(self):\n",
    "#         file_format = self._get_file_format()\n",
    "\n",
    "#         if file_format == 'doc':\n",
    "#             return self._convert_doc_to_text()\n",
    "#         elif file_format == 'docx':\n",
    "#             return self._convert_docx_to_text()\n",
    "#         elif file_format == 'pdf':\n",
    "#             return self._convert_pdf_to_text()\n",
    "#         else:\n",
    "#             return \"Unsupported file format\"\n",
    "\n",
    "#     def _get_file_path(self):\n",
    "#         if os.path.isfile(self.file_identifier):\n",
    "#             return self.file_identifier\n",
    "#         elif 'http' in self.file_identifier:\n",
    "#             # If the identifier is a URL, download the file\n",
    "#             file_name = self.file_identifier.split('/')[-1]\n",
    "#             response = self._download_file(self.file_identifier, file_name)\n",
    "\n",
    "#             if response and response.status_code == 200:\n",
    "#                 return file_name\n",
    "#             else:\n",
    "#                 return None\n",
    "#         else:\n",
    "#             # Assume the identifier is a filename in the current directory\n",
    "#             current_directory = os.getcwd()\n",
    "#             file_path = os.path.join(current_directory, self.file_identifier)\n",
    "\n",
    "#             if os.path.isfile(file_path):\n",
    "#                 return file_path\n",
    "#             else:\n",
    "#                 return None\n",
    "\n",
    "#     def _download_file(self, url, file_name):\n",
    "#         try:\n",
    "#             response = requests.get(url)\n",
    "#             with open(file_name, 'wb') as file:\n",
    "#                 file.write(response.content)\n",
    "#             return response\n",
    "#         except Exception as e:\n",
    "#             print(f\"Error downloading file: {str(e)}\")\n",
    "#             return None\n",
    "\n",
    "#     def _get_file_format(self):\n",
    "#         if self.file_path.lower().endswith('.doc'):\n",
    "#             return 'doc'\n",
    "#         elif self.file_path.lower().endswith('.docx'):\n",
    "#             return 'docx'\n",
    "#         elif self.file_path.lower().endswith('.pdf'):\n",
    "#             return 'pdf'\n",
    "#         else:\n",
    "#             return None\n",
    "\n",
    "#     def _convert_doc_to_text(self):\n",
    "#         try:\n",
    "#             text = docx2txt.process(self.file_path)\n",
    "#             return text\n",
    "#         except Exception as e:\n",
    "#             return f\"Error converting DOC to text: {str(e)}\"\n",
    "\n",
    "#     def _convert_docx_to_text(self):\n",
    "#         try:\n",
    "#             with open(self.file_path, 'rb') as file:\n",
    "#                 doc = docx.Document(file)\n",
    "#                 text = \"\"\n",
    "#                 for para in doc.paragraphs:\n",
    "#                     text += para.text + '\\n'\n",
    "#                 return text\n",
    "#         except Exception as e:\n",
    "#             return f\"Error converting DOCX to text: {str(e)}\"\n",
    "\n",
    "#     def _convert_pdf_to_text(self):\n",
    "#         try:\n",
    "#             with open(self.file_path, 'rb') as file:\n",
    "#                 pdf_reader = PdfReader(file)\n",
    "#                 text = \"\"\n",
    "#                 for page_num in range(len(pdf_reader.pages)):\n",
    "#                     text += pdf_reader.pages[page_num].extract_text()\n",
    "#                 return text\n",
    "#         except Exception as e:\n",
    "#             return f\"Error converting PDF to text: {str(e)}\"\n",
    "\n",
    "# # Пример использования\n",
    "# file_identifier = 'Резюме для 1 кейса Хакатона/Alan Abdirasul.pdf'\n",
    "# converter = FileConverterService()\n",
    "# result = converter.execute(file_identifier)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "1ae95383-ecf6-4dc6-a2c5-bf136e4e7976",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "OpenAI Password:  ········\n"
     ]
    }
   ],
   "source": [
    "# api_key = getpass(prompt='GigaChad Password: ')\n",
    "# gigachad = GigaChat(credentials=api_key, scope=\"GIGACHAT_API_PERS\", verify_ssl_certs=True, model=\"GigaChat-Pro\")\n",
    "\n",
    "api_key = getpass(prompt='OpenAI Password: ')\n",
    "openai = ChatOpenAI(temperature=0.0, api_key=api_key, model_name=\"gpt-3.5-turbo-instruct\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "6ebe1ffa-13ef-45c9-9a1f-f06e518f3440",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Contact(BaseModel):\n",
    "    resume_contact_item_id: str = Field(description=\"ID\")\n",
    "    value: str = Field(description=\"Значение\")\n",
    "    comment: str = Field(description=\"Комментарий\")\n",
    "    contact_type: str = Field(description=\"Тип контакта (1: Телефон, 2: Email, 3: Skype, 4: Telegram, 5: Github)\")\n",
    "\n",
    "class Education(BaseModel):\n",
    "    resume_education_item_id: str = Field(description=\"ID\")\n",
    "    year: str = Field(description=\"Год окончания\")\n",
    "    organization: str = Field(description=\"Название учебного заведения\")\n",
    "    faculty: str = Field(description=\"Факультет\")\n",
    "    specialty: str = Field(description=\"Специальность\")\n",
    "    result: str = Field(description=\"Результат обучения\")\n",
    "    education_type: str = Field(description=\"Тип образования\", enum = [\"Начальное\", \"Повышение квалификации\", \"Сертификаты\", \"Основное\"])\n",
    "    education_level: str = Field(description=\"Уровень образования\", enum = [\"Среднее\", \"Среднее специальное\", \"Неоконченное высшее\", \"Высшее, Бакалавр\", \"Магистр\", \"Кандидат наук\", \"Доктор наук\"])\n",
    "\n",
    "class Experience(BaseModel):\n",
    "    resume_experience_item_id: str = Field(description=\"ID\")\n",
    "    starts: str = Field(description=\"Год начала\")\n",
    "    ends: str = Field(description=\"Год окончания\")\n",
    "    employer: str = Field(description=\"Организация\")\n",
    "    city: str = Field(description=\"Город\")\n",
    "    url: str = Field(description=\"Ссылка на сайт работодателя\")\n",
    "    position: str = Field(description=\"Должность\")\n",
    "    description: str = Field(description=\"Описание\")\n",
    "    order: str = Field(description=\"Порядок следования в массиве опыта работы (для сортировки)\") # TUT CHTOT SDELAT NODO\n",
    "\n",
    "class Language(BaseModel):\n",
    "    resume_language_item_id: str = Field(description=\"ID\")\n",
    "    language: str = Field(description=\"Язык\")\n",
    "    language_level: str = Field(description=\"Уровень владения языком\", enum=[\"Начальный\", \"Элементарный\", \"Средний\", \"Средне-продвинутый\", \"Продвинутый\", \"В совершенстве\", \"Родной\"])\n",
    "\n",
    "class Resume(BaseModel):\n",
    "    resume_id: str = Field(description=\"ID резюме\")\n",
    "    first_name: str = Field(description=\"Имя\")\n",
    "    last_name: str = Field(description=\"Фамилия\")\n",
    "    middle_name: str = Field(description=\"Отчество\")\n",
    "    birth_date: str = Field(description=\"Дата рождения в формате YYYY-MM-DD\")\n",
    "    birth_date_year_only: bool = Field(description=\"Если true, дата рождения вычисляется из возраста (Например, возраст 20 -> 2004-01-01)\")\n",
    "    country: str = Field(description=\"Страна\")\n",
    "    city: str = Field(description=\"Город\")\n",
    "    about: str = Field(description=\"Описание\")\n",
    "    key_skills: str = Field(description=\"Ключевые навыки\")\n",
    "    salary_expectations_amount: str = Field(description=\"Зарплатные ожидания\")\n",
    "    salary_expectations_currency: str = Field(description=\"Валюта зарплатных ожиданий\")\n",
    "    photo_path: str = Field(description=\"Ссылка на фото\")\n",
    "    gender: str = Field(description=\"Пол {1: Мужской, 2: Женский}\")\n",
    "    resume_name: str = Field(description=\"Название резюме\")\n",
    "    source_link: str = Field(description=\"Ссылка на источник резюме\")\n",
    "    contact: List[Contact] = Field(description=\"Контактные данные\")\n",
    "    education: List[Education] = Field(description=\"Образование\")\n",
    "    experience: List[Experience] = Field(description=\"Опыт работы\")\n",
    "    language: List[Language] = Field(description=\"Владение иностранными языками\")\n",
    "\n",
    "\n",
    "parser = JsonOutputParser(pydantic_object=Resume)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "208c01ce-6e19-44d3-8782-f5d436b21381",
   "metadata": {},
   "outputs": [],
   "source": [
    "instructions = parser.get_format_instructions()\n",
    "decoded_instructions = bytes(instructions, \"utf-8\").decode(\"unicode_escape\")\n",
    "\n",
    "prompt_template = \"\"\"Из следующего текста извлеки информацию:\n",
    "\n",
    "###\n",
    "\n",
    "text: {text}\n",
    "\n",
    "###\n",
    "\n",
    "{format_instructions}\n",
    "\n",
    "\"\"\"\n",
    "\n",
    "prompt = PromptTemplate(\n",
    "    template=prompt_template,\n",
    "    input_variables=[\"text\"],\n",
    "    partial_variables={\"format_instructions\": decoded_instructions},\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "9275f70d-2602-49ef-96fb-82321a74e74e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'resume_id': '123456789',\n",
       " 'first_name': 'Alan',\n",
       " 'last_name': 'Abdirasul',\n",
       " 'middle_name': 'Senior Java Software Engineer',\n",
       " 'birth_date': '1990-01-01',\n",
       " 'birth_date_year_only': False,\n",
       " 'country': 'USA',\n",
       " 'city': 'Chicago',\n",
       " 'about': 'Experienced Software Engineer with 5+ years of experience participating in all aspects of the software development lifecycle.',\n",
       " 'key_skills': 'Java, Kotlin, JavaScript, Spring boot, WebFlux, Gradle, Maven, RabbitMQ, Kafka, WebSocket, Spring Cloud, Hibernate, GraphQL, gRPC, React, Redux, HTML, CSS, Git, Github, Gitlab, CodeCommit, CI/CD, Docker, Kubernetes, AWS',\n",
       " 'salary_expectations_amount': '100000',\n",
       " 'salary_expectations_currency': 'USD',\n",
       " 'photo_path': 'https://example.com/photo.jpg',\n",
       " 'gender': '1',\n",
       " 'resume_name': 'Senior Java Software Engineer',\n",
       " 'source_link': 'https://example.com/resume',\n",
       " 'contact': [{'resume_contact_item_id': '1',\n",
       "   'value': 'aаааааааbdirasul@gmail.com',\n",
       "   'comment': 'Primary Email',\n",
       "   'contact_type': '2'}],\n",
       " 'education': [{'resume_education_item_id': '1',\n",
       "   'year': '2020',\n",
       "   'organization': 'Kirgizistan-Türkiye Manas Üniversitesi',\n",
       "   'faculty': 'Computer Science',\n",
       "   'specialty': \"Bachelor's Degree\",\n",
       "   'result': 'Graduated with honors',\n",
       "   'education_type': 'Основное',\n",
       "   'education_level': 'Высшее, Бакалавр'}],\n",
       " 'experience': [{'resume_experience_item_id': '1',\n",
       "   'starts': '2022',\n",
       "   'ends': 'Present',\n",
       "   'employer': 'Peaksoft',\n",
       "   'city': 'Chicago',\n",
       "   'url': 'https://peaksoft.com',\n",
       "   'position': 'Lead Java Software Engineer',\n",
       "   'description': 'Deployed and scaled applications on AWS, managed task assignments, introduced pair programming, orchestrated microservices architecture, mentored junior developers.',\n",
       "   'order': '1'},\n",
       "  {'resume_experience_item_id': '2',\n",
       "   'starts': '2021',\n",
       "   'ends': '2022',\n",
       "   'employer': 'Peaksoft',\n",
       "   'city': 'Chicago',\n",
       "   'url': 'https://peaksoft.com',\n",
       "   'position': 'Senior Software Engineer',\n",
       "   'description': 'Enhanced application responsiveness, integrated third-party systems, optimized Grafana deployments, automated software delivery processes.',\n",
       "   'order': '2'},\n",
       "  {'resume_experience_item_id': '3',\n",
       "   'starts': '2020',\n",
       "   'ends': '2021',\n",
       "   'employer': 'Inclusive Technology',\n",
       "   'city': 'Bishkek',\n",
       "   'url': 'https://inclusive-tech.com',\n",
       "   'position': 'Software Engineer',\n",
       "   'description': 'Optimized workflows, orchestrated efficient communication, guided junior developers, engineered innovative features.',\n",
       "   'order': '3'},\n",
       "  {'resume_experience_item_id': '4',\n",
       "   'starts': '2018',\n",
       "   'ends': '2020',\n",
       "   'employer': 'Aksoft',\n",
       "   'city': 'Bishkek',\n",
       "   'url': 'https://aksoft.com',\n",
       "   'position': 'Full-Stack Developer',\n",
       "   'description': 'Developed scalable applications, optimized database designs, collaborated with cross-functional teams, implemented CI/CD pipelines, leveraged Docker for containerization.',\n",
       "   'order': '4'}],\n",
       " 'language': [{'resume_language_item_id': '1',\n",
       "   'language': 'English',\n",
       "   'language_level': 'Продвинутый'},\n",
       "  {'resume_language_item_id': '2',\n",
       "   'language': 'Russian',\n",
       "   'language_level': 'Продвинутый'}]}"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chain = prompt | openai | parser\n",
    "chain.invoke({\"text\": result})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "42dd7689-0990-4550-9927-e5e458c3ec67",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Из следующего текста извлеки информацию:\n",
      "\n",
      "###\n",
      "\n",
      "text: Alan Abdirasul Senior Java Software Engineer |aаааааааbdirasul@gmail.com Summary  Experienced Software Engineer with 5+ years of experience participating in all aspects of the software development lifecycle, which includes estimating, technical design, implementation documentation, testing, deployment, and support of applications developed for various clients. Skills    • Programming Languages: Java, Kotlin, JavaScript, TypeScript • Backend Technologies: Spring boot, WebFlux, Gradle, Maven, RabbitMQ, Kafka, WebSocket, Spring Cloud, Hibernate, GraphQL, gRPC • Databases: PostgreSql, MySql, MongoDB, Redis, Oracle Database, R2DBC • Frontend Technologies: React, Redux, HTML, CSS • Software development tools: Git, Github, Gitlab, CodeCommit, CI/CD, CircleCi, Jenkins, Grafana, Prometheus, Graphite, JUnit, Mockito • Cloud: Docker, Kubernetes, AWS, Digital Ocean • Soft Skills: Leadership, communication, problem-solving, adaptability, teamwork, time management, critical thinking, emotional intelligence. Experience    Lead Java Software Engineer Peaksoft Chicago, Illinois USA(Remote) 05/2022 - Present • Deployed and scaled applications on AWS. • Effectively communicated within a multi-disciplined team, across 23 locations and 5 time zones. • Managed task assignments and priorities for timely deliveries. • Collaborated with stakeholders to prioritize system enhancements, boosting business process efficiency by 27%. • Introduced pair programming, elevating code quality by 35% and accelerating project delivery. • Orchestrated successful implementation of microservices architecture for improved scalability. • Mentored and supported 18 junior and middle developers, enhancing code quality by 30%.  Senior Software Engineer Peaksoft Chicago, Illinois USA(Remote) 05/2021 - 05/2022 • Enhanced application responsiveness and scalability through algorithm optimization.. • Skillfully integrated third-party systems, contributing to a 23% increase in global revenue. • IImplemented and optimized Grafana deployments, elevating application monitoring capabilities. • Automated software delivery processes using CircleCI for efficient deployment.  Software Engineer Inclusive Technology Bishkek, Kyrgyzstan(On-site) 11/2020 - 06/2021 • Optimized workflows, reducing development time by 25%. • Orchestrated efficient communication across frontend, backend, and AQA teams, advancing deadlines by 12%. • Guided 6 junior and middle developers, fostering growth and development. • Engineered innovative features, including real-time grammar checking. Full-Stack Developer Aksoft Bishkek, Kyrgyzstan(On-site) 05/2018 - 11/2020 • Developed scalable applications using Java, JavaScript, React.js, and Redux.js. • Optimized database designs and query performance, resulting in more efficient data management. • Collaborated with cross-functional teams to gather requirements and deliver solutions tailored to client needs. • Implemented CI/CD pipelines using CircleCI, achieving a significant 70% boost in deployment efficiency. • Leveraged Docker for containerization, which reduced deployment time by 32% while improving the app's scalability.. • Managed projects efficiently through the use of Gradle and Maven, facilitating coordinated efforts. • Leveraged Amazon S3 to enhance metadata storage and retrieval within Spring MVC projects.  Education    Computer Science, Bachelor's Degree Kirgizistan-Türkiye Manas Üniversitesi 09/2017 - 09/2020 Mentorship    • CodeWise Academy: I employed interactive teaching methods, real-world examples, and hands-on coding projects to enhance students' grasp of Java programming concepts. I led face-to-face Zoom sessions accommodating diverse language preferences, inspire critical thinking, conduct assessments, and have successfully guided over 180 students, with 87 securing jobs, fostering their growth through mentoring and code reviews. (09/2022 - Present) • Avenir Education Company: Instructed students in backend development (Spring, Java, JDBC), guiding coding assignments, configuring CI/CD pipelines, and leading projects. Mentored 300+ students in web development with Java-based backend systems, conducting code reviews and providing career advice for success. (03/2020 - 01/2022) \n",
      "\n",
      "###\n",
      "\n",
      "The output should be formatted as a JSON instance that conforms to the JSON schema below.\n",
      "\n",
      "As an example, for the schema {\"properties\": {\"foo\": {\"title\": \"Foo\", \"description\": \"a list of strings\", \"type\": \"array\", \"items\": {\"type\": \"string\"}}}, \"required\": [\"foo\"]}\n",
      "the object {\"foo\": [\"bar\", \"baz\"]} is a well-formatted instance of the schema. The object {\"properties\": {\"foo\": [\"bar\", \"baz\"]}} is not well-formatted.\n",
      "\n",
      "Here is the output schema:\n",
      "```\n",
      "{\"properties\": {\"resume_id\": {\"title\": \"Resume Id\", \"description\": \"ID резюме\", \"type\": \"string\"}, \"first_name\": {\"title\": \"First Name\", \"description\": \"Имя\", \"type\": \"string\"}, \"last_name\": {\"title\": \"Last Name\", \"description\": \"Фамилия\", \"type\": \"string\"}, \"middle_name\": {\"title\": \"Middle Name\", \"description\": \"Отчество\", \"type\": \"string\"}, \"birth_date\": {\"title\": \"Birth Date\", \"description\": \"Дата рождения в формате YYYY-MM-DD\", \"type\": \"string\"}, \"birth_date_year_only\": {\"title\": \"Birth Date Year Only\", \"description\": \"Если true, дата рождения вычисляется из возраста (Например, возраст 20 -> 2004-01-01)\", \"type\": \"boolean\"}, \"country\": {\"title\": \"Country\", \"description\": \"Страна\", \"type\": \"string\"}, \"city\": {\"title\": \"City\", \"description\": \"Город\", \"type\": \"string\"}, \"about\": {\"title\": \"About\", \"description\": \"Описание\", \"type\": \"string\"}, \"key_skills\": {\"title\": \"Key Skills\", \"description\": \"Ключевые навыки\", \"type\": \"string\"}, \"salary_expectations_amount\": {\"title\": \"Salary Expectations Amount\", \"description\": \"Зарплатные ожидания\", \"type\": \"string\"}, \"salary_expectations_currency\": {\"title\": \"Salary Expectations Currency\", \"description\": \"Валюта зарплатных ожиданий\", \"type\": \"string\"}, \"photo_path\": {\"title\": \"Photo Path\", \"description\": \"Ссылка на фото\", \"type\": \"string\"}, \"gender\": {\"title\": \"Gender\", \"description\": \"Пол {1: Мужской, 2: Женский}\", \"type\": \"string\"}, \"resume_name\": {\"title\": \"Resume Name\", \"description\": \"Название резюме\", \"type\": \"string\"}, \"source_link\": {\"title\": \"Source Link\", \"description\": \"Ссылка на источник резюме\", \"type\": \"string\"}, \"contact\": {\"title\": \"Contact\", \"description\": \"Контактные данные\", \"type\": \"array\", \"items\": {\"$ref\": \"#/definitions/Contact\"}}, \"education\": {\"title\": \"Education\", \"description\": \"Образование\", \"type\": \"array\", \"items\": {\"$ref\": \"#/definitions/Education\"}}, \"experience\": {\"title\": \"Experience\", \"description\": \"Опыт работы\", \"type\": \"array\", \"items\": {\"$ref\": \"#/definitions/Experience\"}}, \"language\": {\"title\": \"Language\", \"description\": \"Владение иностранными языками\", \"type\": \"array\", \"items\": {\"$ref\": \"#/definitions/Language\"}}}, \"required\": [\"resume_id\", \"first_name\", \"last_name\", \"middle_name\", \"birth_date\", \"birth_date_year_only\", \"country\", \"city\", \"about\", \"key_skills\", \"salary_expectations_amount\", \"salary_expectations_currency\", \"photo_path\", \"gender\", \"resume_name\", \"source_link\", \"contact\", \"education\", \"experience\", \"language\"], \"definitions\": {\"Contact\": {\"title\": \"Contact\", \"type\": \"object\", \"properties\": {\"resume_contact_item_id\": {\"title\": \"Resume Contact Item Id\", \"description\": \"ID\", \"type\": \"string\"}, \"value\": {\"title\": \"Value\", \"description\": \"Значение\", \"type\": \"string\"}, \"comment\": {\"title\": \"Comment\", \"description\": \"Комментарий\", \"type\": \"string\"}, \"contact_type\": {\"title\": \"Contact Type\", \"description\": \"Тип контакта (1: Телефон, 2: Email, 3: Skype, 4: Telegram, 5: Github)\", \"type\": \"string\"}}, \"required\": [\"resume_contact_item_id\", \"value\", \"comment\", \"contact_type\"]}, \"Education\": {\"title\": \"Education\", \"type\": \"object\", \"properties\": {\"resume_education_item_id\": {\"title\": \"Resume Education Item Id\", \"description\": \"ID\", \"type\": \"string\"}, \"year\": {\"title\": \"Year\", \"description\": \"Год окончания\", \"type\": \"string\"}, \"organization\": {\"title\": \"Organization\", \"description\": \"Название учебного заведения\", \"type\": \"string\"}, \"faculty\": {\"title\": \"Faculty\", \"description\": \"Факультет\", \"type\": \"string\"}, \"specialty\": {\"title\": \"Specialty\", \"description\": \"Специальность\", \"type\": \"string\"}, \"result\": {\"title\": \"Result\", \"description\": \"Результат обучения\", \"type\": \"string\"}, \"education_type\": {\"title\": \"Education Type\", \"description\": \"Тип образования\", \"enum\": [\"Начальное\", \"Повышение квалификации\", \"Сертификаты\", \"Основное\"], \"type\": \"string\"}, \"education_level\": {\"title\": \"Education Level\", \"description\": \"Уровень образования\", \"enum\": [\"Среднее\", \"Среднее специальное\", \"Неоконченное высшее\", \"Высшее, Бакалавр\", \"Магистр\", \"Кандидат наук\", \"Доктор наук\"], \"type\": \"string\"}}, \"required\": [\"resume_education_item_id\", \"year\", \"organization\", \"faculty\", \"specialty\", \"result\", \"education_type\", \"education_level\"]}, \"Experience\": {\"title\": \"Experience\", \"type\": \"object\", \"properties\": {\"resume_experience_item_id\": {\"title\": \"Resume Experience Item Id\", \"description\": \"ID\", \"type\": \"string\"}, \"starts\": {\"title\": \"Starts\", \"description\": \"Год начала\", \"type\": \"string\"}, \"ends\": {\"title\": \"Ends\", \"description\": \"Год окончания\", \"type\": \"string\"}, \"employer\": {\"title\": \"Employer\", \"description\": \"Организация\", \"type\": \"string\"}, \"city\": {\"title\": \"City\", \"description\": \"Город\", \"type\": \"string\"}, \"url\": {\"title\": \"Url\", \"description\": \"Ссылка на сайт работодателя\", \"type\": \"string\"}, \"position\": {\"title\": \"Position\", \"description\": \"Должность\", \"type\": \"string\"}, \"description\": {\"title\": \"Description\", \"description\": \"Описание\", \"type\": \"string\"}, \"order\": {\"title\": \"Order\", \"description\": \"Порядок следования в массиве опыта работы (для сортировки)\", \"type\": \"string\"}}, \"required\": [\"resume_experience_item_id\", \"starts\", \"ends\", \"employer\", \"city\", \"url\", \"position\", \"description\", \"order\"]}, \"Language\": {\"title\": \"Language\", \"type\": \"object\", \"properties\": {\"resume_language_item_id\": {\"title\": \"Resume Language Item Id\", \"description\": \"ID\", \"type\": \"string\"}, \"language\": {\"title\": \"Language\", \"description\": \"Язык\", \"type\": \"string\"}, \"language_level\": {\"title\": \"Language Level\", \"description\": \"Уровень владения языком\", \"enum\": [\"Начальный\", \"Элементарный\", \"Средний\", \"Средне-продвинутый\", \"Продвинутый\", \"В совершенстве\", \"Родной\"], \"type\": \"string\"}}, \"required\": [\"resume_language_item_id\", \"language\", \"language_level\"]}}}\n",
      "```\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(prompt.format(text = result))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "b2eeb6ef-8327-4aa7-997e-9fa1c68bb379",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting unstructured[pdf]\n",
      "  Downloading unstructured-0.11.8-py3-none-any.whl.metadata (26 kB)\n",
      "Collecting chardet (from unstructured[pdf])\n",
      "  Downloading chardet-5.2.0-py3-none-any.whl.metadata (3.4 kB)\n",
      "Collecting filetype (from unstructured[pdf])\n",
      "  Downloading filetype-1.2.0-py2.py3-none-any.whl.metadata (6.5 kB)\n",
      "Collecting python-magic (from unstructured[pdf])\n",
      "  Downloading python_magic-0.4.27-py2.py3-none-any.whl.metadata (5.8 kB)\n",
      "Collecting lxml (from unstructured[pdf])\n",
      "  Downloading lxml-5.1.0-cp312-cp312-macosx_10_9_x86_64.whl.metadata (3.5 kB)\n",
      "Collecting nltk (from unstructured[pdf])\n",
      "  Downloading nltk-3.8.1-py3-none-any.whl.metadata (2.8 kB)\n",
      "Collecting tabulate (from unstructured[pdf])\n",
      "  Downloading tabulate-0.9.0-py3-none-any.whl.metadata (34 kB)\n",
      "Requirement already satisfied: requests in /Users/naesalang/miniconda3/envs/openai/lib/python3.12/site-packages (from unstructured[pdf]) (2.31.0)\n",
      "Collecting beautifulsoup4 (from unstructured[pdf])\n",
      "  Downloading beautifulsoup4-4.12.3-py3-none-any.whl.metadata (3.8 kB)\n",
      "Collecting emoji (from unstructured[pdf])\n",
      "  Downloading emoji-2.10.1-py2.py3-none-any.whl.metadata (5.3 kB)\n",
      "Requirement already satisfied: dataclasses-json in /Users/naesalang/miniconda3/envs/openai/lib/python3.12/site-packages (from unstructured[pdf]) (0.6.4)\n",
      "Collecting python-iso639 (from unstructured[pdf])\n",
      "  Downloading python_iso639-2024.2.7-py3-none-any.whl.metadata (13 kB)\n",
      "Collecting langdetect (from unstructured[pdf])\n",
      "  Downloading langdetect-1.0.9.tar.gz (981 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m981.5/981.5 kB\u001b[0m \u001b[31m913.0 kB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25hRequirement already satisfied: numpy in /Users/naesalang/miniconda3/envs/openai/lib/python3.12/site-packages (from unstructured[pdf]) (1.26.4)\n",
      "Collecting rapidfuzz (from unstructured[pdf])\n",
      "  Downloading rapidfuzz-3.6.1-cp312-cp312-macosx_10_9_x86_64.whl.metadata (11 kB)\n",
      "Collecting backoff (from unstructured[pdf])\n",
      "  Downloading backoff-2.2.1-py3-none-any.whl.metadata (14 kB)\n",
      "Requirement already satisfied: typing-extensions in /Users/naesalang/miniconda3/envs/openai/lib/python3.12/site-packages (from unstructured[pdf]) (4.10.0)\n",
      "Collecting unstructured-client (from unstructured[pdf])\n",
      "  Downloading unstructured_client-0.18.0-py3-none-any.whl.metadata (4.9 kB)\n",
      "Collecting wrapt (from unstructured[pdf])\n",
      "  Downloading wrapt-1.16.0-cp312-cp312-macosx_10_9_x86_64.whl.metadata (6.6 kB)\n",
      "Collecting onnx (from unstructured[pdf])\n",
      "  Downloading onnx-1.15.0.tar.gz (12.3 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m12.3/12.3 MB\u001b[0m \u001b[31m4.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25h  Installing build dependencies ... \u001b[?25ldone\n",
      "\u001b[?25h  Getting requirements to build wheel ... \u001b[?25ldone\n",
      "\u001b[?25h  Installing backend dependencies ... \u001b[?25ldone\n",
      "\u001b[?25h  Preparing metadata (pyproject.toml) ... \u001b[?25ldone\n",
      "\u001b[?25hCollecting pdf2image (from unstructured[pdf])\n",
      "  Downloading pdf2image-1.17.0-py3-none-any.whl.metadata (6.2 kB)\n",
      "Collecting pdfminer.six (from unstructured[pdf])\n",
      "  Downloading pdfminer.six-20231228-py3-none-any.whl.metadata (4.2 kB)\n",
      "Collecting pikepdf (from unstructured[pdf])\n",
      "  Downloading pikepdf-8.13.0-cp312-cp312-macosx_10_9_x86_64.whl.metadata (8.6 kB)\n",
      "Collecting pypdf (from unstructured[pdf])\n",
      "  Downloading pypdf-4.0.2-py3-none-any.whl.metadata (7.4 kB)\n",
      "Collecting unstructured-inference==0.7.18 (from unstructured[pdf])\n",
      "  Downloading unstructured_inference-0.7.18-py3-none-any.whl.metadata (6.6 kB)\n",
      "Collecting unstructured.pytesseract>=0.3.12 (from unstructured[pdf])\n",
      "  Downloading unstructured.pytesseract-0.3.12-py3-none-any.whl.metadata (11 kB)\n",
      "Collecting layoutparser[layoutmodels,tesseract] (from unstructured-inference==0.7.18->unstructured[pdf])\n",
      "  Downloading layoutparser-0.3.4-py3-none-any.whl.metadata (7.7 kB)\n",
      "Collecting python-multipart (from unstructured-inference==0.7.18->unstructured[pdf])\n",
      "  Downloading python_multipart-0.0.9-py3-none-any.whl.metadata (2.5 kB)\n",
      "Collecting huggingface-hub (from unstructured-inference==0.7.18->unstructured[pdf])\n",
      "  Downloading huggingface_hub-0.21.2-py3-none-any.whl.metadata (13 kB)\n",
      "Collecting opencv-python!=4.7.0.68 (from unstructured-inference==0.7.18->unstructured[pdf])\n",
      "  Downloading opencv_python-4.9.0.80-cp37-abi3-macosx_10_16_x86_64.whl.metadata (20 kB)\n",
      "INFO: pip is looking at multiple versions of unstructured-inference to determine which version is compatible with other requirements. This could take a while.\n",
      "Collecting unstructured[pdf]\n",
      "  Downloading unstructured-0.11.7-py3-none-any.whl.metadata (26 kB)\n",
      "  Downloading unstructured-0.11.6-py3-none-any.whl.metadata (26 kB)\n",
      "  Downloading unstructured-0.11.5-py3-none-any.whl.metadata (26 kB)\n",
      "  Downloading unstructured-0.11.4-py3-none-any.whl.metadata (26 kB)\n",
      "  Downloading unstructured-0.11.2-py3-none-any.whl.metadata (25 kB)\n",
      "Collecting unstructured-inference==0.7.15 (from unstructured[pdf])\n",
      "  Downloading unstructured_inference-0.7.15-py3-none-any.whl.metadata (6.6 kB)\n",
      "Collecting unstructured[pdf]\n",
      "  Downloading unstructured-0.11.1-py3-none-any.whl.metadata (25 kB)\n",
      "  Downloading unstructured-0.11.0-py3-none-any.whl.metadata (25 kB)\n",
      "INFO: pip is still looking at multiple versions of unstructured-inference to determine which version is compatible with other requirements. This could take a while.\n",
      "  Downloading unstructured-0.10.30-py3-none-any.whl.metadata (25 kB)\n",
      "Collecting unstructured-inference==0.7.11 (from unstructured[pdf])\n",
      "  Downloading unstructured_inference-0.7.11-py3-none-any.whl.metadata (6.8 kB)\n",
      "Collecting unstructured[pdf]\n",
      "  Downloading unstructured-0.10.29-py3-none-any.whl.metadata (25 kB)\n",
      "  Downloading unstructured-0.10.28-py3-none-any.whl.metadata (25 kB)\n",
      "Collecting unstructured-inference==0.7.10 (from unstructured[pdf])\n",
      "  Downloading unstructured_inference-0.7.10-py3-none-any.whl.metadata (6.8 kB)\n",
      "Collecting unstructured[pdf]\n",
      "  Downloading unstructured-0.10.27-py3-none-any.whl.metadata (25 kB)\n",
      "  Downloading unstructured-0.10.26-py3-none-any.whl.metadata (25 kB)\n",
      "INFO: This is taking longer than usual. You might need to provide the dependency resolver with stricter constraints to reduce runtime. See https://pip.pypa.io/warnings/backtracking for guidance. If you want to abort this run, press Ctrl + C.\n",
      "  Downloading unstructured-0.10.25-py3-none-any.whl.metadata (25 kB)\n",
      "Collecting unstructured-inference==0.7.9 (from unstructured[pdf])\n",
      "  Downloading unstructured_inference-0.7.9-py3-none-any.whl.metadata (6.8 kB)\n",
      "Collecting unstructured[pdf]\n",
      "  Downloading unstructured-0.10.24-py3-none-any.whl.metadata (25 kB)\n",
      "Collecting unstructured-inference==0.7.7 (from unstructured[pdf])\n",
      "  Downloading unstructured_inference-0.7.7-py3-none-any.whl.metadata (6.8 kB)\n",
      "Collecting unstructured[pdf]\n",
      "  Downloading unstructured-0.10.23-py3-none-any.whl.metadata (25 kB)\n",
      "Collecting unstructured-inference==0.7.5 (from unstructured[pdf])\n",
      "  Downloading unstructured_inference-0.7.5-py3-none-any.whl.metadata (6.8 kB)\n",
      "Collecting unstructured[pdf]\n",
      "  Downloading unstructured-0.10.22-py3-none-any.whl.metadata (24 kB)\n",
      "Collecting unstructured-inference==0.7.3 (from unstructured[pdf])\n",
      "  Downloading unstructured_inference-0.7.3-py3-none-any.whl.metadata (6.7 kB)\n",
      "Collecting onnx==1.14.1 (from unstructured-inference==0.7.3->unstructured[pdf])\n",
      "  Downloading onnx-1.14.1.tar.gz (11.3 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m11.3/11.3 MB\u001b[0m \u001b[31m6.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25h  Installing build dependencies ... \u001b[?25ldone\n",
      "\u001b[?25h  Getting requirements to build wheel ... \u001b[?25ldone\n",
      "\u001b[?25h  Installing backend dependencies ... \u001b[?25ldone\n",
      "\u001b[?25h  Preparing metadata (pyproject.toml) ... \u001b[?25ldone\n",
      "\u001b[?25hCollecting unstructured[pdf]\n",
      "  Downloading unstructured-0.10.21-py3-none-any.whl.metadata (24 kB)\n",
      "Collecting unstructured-inference==0.7.2 (from unstructured[pdf])\n",
      "  Downloading unstructured_inference-0.7.2-py3-none-any.whl.metadata (6.7 kB)\n",
      "Collecting unstructured[pdf]\n",
      "  Downloading unstructured-0.10.20-py3-none-any.whl.metadata (24 kB)\n",
      "  Downloading unstructured-0.10.19-py3-none-any.whl.metadata (24 kB)\n",
      "Collecting unstructured-inference==0.6.6 (from unstructured[pdf])\n",
      "  Downloading unstructured_inference-0.6.6-py3-none-any.whl.metadata (6.6 kB)\n",
      "Collecting unstructured[pdf]\n",
      "  Downloading unstructured-0.10.18-py3-none-any.whl.metadata (24 kB)\n",
      "Collecting unstructured-inference==0.5.31 (from unstructured[pdf])\n",
      "  Downloading unstructured_inference-0.5.31-py3-none-any.whl.metadata (6.6 kB)\n",
      "Collecting unstructured[pdf]\n",
      "  Downloading unstructured-0.10.16-py3-none-any.whl.metadata (23 kB)\n",
      "Collecting unstructured-inference (from unstructured[pdf])\n",
      "  Downloading unstructured_inference-0.7.24-py3-none-any.whl.metadata (5.8 kB)\n",
      "  Downloading unstructured_inference-0.7.23-py3-none-any.whl.metadata (5.8 kB)\n",
      "  Downloading unstructured_inference-0.7.21-py3-none-any.whl.metadata (5.8 kB)\n",
      "  Downloading unstructured_inference-0.7.20-py3-none-any.whl.metadata (5.8 kB)\n",
      "  Downloading unstructured_inference-0.7.19-py3-none-any.whl.metadata (5.8 kB)\n",
      "  Downloading unstructured_inference-0.7.17-py3-none-any.whl.metadata (6.6 kB)\n",
      "  Downloading unstructured_inference-0.7.16-py3-none-any.whl.metadata (6.6 kB)\n",
      "  Downloading unstructured_inference-0.7.14-py3-none-any.whl.metadata (6.6 kB)\n",
      "  Downloading unstructured_inference-0.7.13-py3-none-any.whl.metadata (6.8 kB)\n",
      "  Downloading unstructured_inference-0.7.12-py3-none-any.whl.metadata (6.8 kB)\n",
      "  Downloading unstructured_inference-0.7.8-py3-none-any.whl.metadata (6.8 kB)\n",
      "  Downloading unstructured_inference-0.7.6-py3-none-any.whl.metadata (6.8 kB)\n",
      "  Downloading unstructured_inference-0.7.4-py3-none-any.whl.metadata (6.7 kB)\n",
      "Collecting super-gradients (from unstructured-inference->unstructured[pdf])\n",
      "  Downloading super_gradients-3.6.0-py3-none-any.whl.metadata (40 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m40.1/40.1 kB\u001b[0m \u001b[31m3.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hCollecting supervision (from unstructured-inference->unstructured[pdf])\n",
      "  Downloading supervision-0.18.0-py3-none-any.whl.metadata (12 kB)\n",
      "Collecting unstructured-inference (from unstructured[pdf])\n",
      "  Downloading unstructured_inference-0.7.1-py3-none-any.whl.metadata (6.7 kB)\n",
      "  Downloading unstructured_inference-0.7.0-py3-none-any.whl.metadata (6.6 kB)\n",
      "  Downloading unstructured_inference-0.6.5-py3-none-any.whl.metadata (6.6 kB)\n",
      "  Downloading unstructured_inference-0.6.4-py3-none-any.whl.metadata (6.6 kB)\n",
      "  Downloading unstructured_inference-0.6.3-py3-none-any.whl.metadata (6.6 kB)\n",
      "  Downloading unstructured_inference-0.6.1-py3-none-any.whl.metadata (6.6 kB)\n",
      "  Downloading unstructured_inference-0.5.28-py3-none-any.whl.metadata (6.6 kB)\n",
      "  Downloading unstructured_inference-0.5.27-py3-none-any.whl.metadata (6.6 kB)\n",
      "  Downloading unstructured_inference-0.5.25-py3-none-any.whl.metadata (6.5 kB)\n",
      "  Downloading unstructured_inference-0.5.24-py3-none-any.whl.metadata (6.5 kB)\n",
      "  Downloading unstructured_inference-0.5.23-py3-none-any.whl.metadata (6.5 kB)\n",
      "  Downloading unstructured_inference-0.5.22-py3-none-any.whl.metadata (6.5 kB)\n",
      "  Downloading unstructured_inference-0.5.21-py3-none-any.whl.metadata (6.5 kB)\n",
      "  Downloading unstructured_inference-0.5.20-py3-none-any.whl.metadata (6.5 kB)\n",
      "  Downloading unstructured_inference-0.5.19-py3-none-any.whl.metadata (6.5 kB)\n",
      "  Downloading unstructured_inference-0.5.18-py3-none-any.whl.metadata (6.5 kB)\n",
      "  Downloading unstructured_inference-0.5.17-py3-none-any.whl.metadata (6.5 kB)\n",
      "  Downloading unstructured_inference-0.5.16-py3-none-any.whl.metadata (6.5 kB)\n",
      "  Downloading unstructured_inference-0.5.15-py3-none-any.whl.metadata (6.5 kB)\n",
      "  Downloading unstructured_inference-0.5.14-py3-none-any.whl.metadata (6.5 kB)\n",
      "  Downloading unstructured_inference-0.5.13-py3-none-any.whl.metadata (6.5 kB)\n",
      "  Downloading unstructured_inference-0.5.12-py3-none-any.whl.metadata (6.5 kB)\n",
      "  Downloading unstructured_inference-0.5.11-py3-none-any.whl.metadata (6.5 kB)\n",
      "  Downloading unstructured_inference-0.5.10-py3-none-any.whl.metadata (6.5 kB)\n",
      "  Downloading unstructured_inference-0.5.9-py3-none-any.whl.metadata (6.5 kB)\n",
      "  Downloading unstructured_inference-0.5.8-py3-none-any.whl.metadata (6.5 kB)\n",
      "  Downloading unstructured_inference-0.5.7-py3-none-any.whl.metadata (6.4 kB)\n",
      "  Downloading unstructured_inference-0.5.6-py3-none-any.whl.metadata (6.4 kB)\n",
      "  Downloading unstructured_inference-0.5.5-py3-none-any.whl.metadata (6.4 kB)\n",
      "  Downloading unstructured_inference-0.5.4-py3-none-any.whl.metadata (6.4 kB)\n",
      "  Downloading unstructured_inference-0.5.3-py3-none-any.whl.metadata (6.4 kB)\n",
      "  Downloading unstructured_inference-0.5.2-py3-none-any.whl.metadata (6.4 kB)\n",
      "  Downloading unstructured_inference-0.5.1-py3-none-any.whl.metadata (6.4 kB)\n",
      "  Downloading unstructured_inference-0.4.4.tar.gz (33 kB)\n",
      "  Preparing metadata (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25hCollecting fastapi (from unstructured-inference->unstructured[pdf])\n",
      "  Using cached fastapi-0.110.0-py3-none-any.whl.metadata (25 kB)\n",
      "Collecting uvicorn (from unstructured-inference->unstructured[pdf])\n",
      "  Downloading uvicorn-0.27.1-py3-none-any.whl.metadata (6.3 kB)\n",
      "Collecting unstructured-inference (from unstructured[pdf])\n",
      "  Downloading unstructured_inference-0.4.2.tar.gz (33 kB)\n",
      "  Preparing metadata (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25h  Downloading unstructured_inference-0.4.1-py3-none-any.whl.metadata (6.2 kB)\n",
      "  Downloading unstructured_inference-0.4.0.tar.gz (32 kB)\n",
      "  Preparing metadata (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25h  Downloading unstructured_inference-0.3.2.tar.gz (31 kB)\n",
      "  Preparing metadata (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25hCollecting opencv-python==4.6.0.66 (from unstructured-inference->unstructured[pdf])\n",
      "  Downloading opencv_python-4.6.0.66-cp36-abi3-macosx_10_15_x86_64.whl.metadata (18 kB)\n",
      "Collecting unstructured-inference (from unstructured[pdf])\n",
      "  Downloading unstructured_inference-0.3.1.tar.gz (31 kB)\n",
      "  Preparing metadata (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25h  Downloading unstructured_inference-0.3.0.tar.gz (30 kB)\n",
      "  Preparing metadata (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25h  Downloading unstructured_inference-0.2.11.tar.gz (17 kB)\n",
      "  Preparing metadata (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25h  Downloading unstructured_inference-0.2.10.tar.gz (17 kB)\n",
      "  Preparing metadata (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25h  Downloading unstructured_inference-0.2.7.tar.gz (18 kB)\n",
      "  Preparing metadata (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25h  Downloading unstructured_inference-0.2.5.tar.gz (17 kB)\n",
      "  Preparing metadata (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25h  Downloading unstructured_inference-0.2.4.tar.gz (10 kB)\n",
      "  Preparing metadata (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25hRequirement already satisfied: packaging>=21.3 in /Users/naesalang/miniconda3/envs/openai/lib/python3.12/site-packages (from unstructured.pytesseract>=0.3.12->unstructured[pdf]) (23.2)\n",
      "Collecting Pillow>=8.0.0 (from unstructured.pytesseract>=0.3.12->unstructured[pdf])\n",
      "  Downloading pillow-10.2.0-cp312-cp312-macosx_10_10_x86_64.whl.metadata (9.7 kB)\n",
      "Collecting soupsieve>1.2 (from beautifulsoup4->unstructured[pdf])\n",
      "  Downloading soupsieve-2.5-py3-none-any.whl.metadata (4.7 kB)\n",
      "Requirement already satisfied: marshmallow<4.0.0,>=3.18.0 in /Users/naesalang/miniconda3/envs/openai/lib/python3.12/site-packages (from dataclasses-json->unstructured[pdf]) (3.21.0)\n",
      "Requirement already satisfied: typing-inspect<1,>=0.4.0 in /Users/naesalang/miniconda3/envs/openai/lib/python3.12/site-packages (from dataclasses-json->unstructured[pdf]) (0.9.0)\n",
      "Collecting click (from nltk->unstructured[pdf])\n",
      "  Using cached click-8.1.7-py3-none-any.whl.metadata (3.0 kB)\n",
      "Collecting joblib (from nltk->unstructured[pdf])\n",
      "  Downloading joblib-1.3.2-py3-none-any.whl.metadata (5.4 kB)\n",
      "Requirement already satisfied: regex>=2021.8.3 in /Users/naesalang/miniconda3/envs/openai/lib/python3.12/site-packages (from nltk->unstructured[pdf]) (2023.12.25)\n",
      "Requirement already satisfied: tqdm in /Users/naesalang/miniconda3/envs/openai/lib/python3.12/site-packages (from nltk->unstructured[pdf]) (4.66.2)\n",
      "Requirement already satisfied: charset-normalizer>=2.0.0 in /Users/naesalang/miniconda3/envs/openai/lib/python3.12/site-packages (from pdfminer.six->unstructured[pdf]) (3.3.2)\n",
      "Collecting cryptography>=36.0.0 (from pdfminer.six->unstructured[pdf])\n",
      "  Downloading cryptography-42.0.5-cp39-abi3-macosx_10_12_universal2.whl.metadata (5.3 kB)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /Users/naesalang/miniconda3/envs/openai/lib/python3.12/site-packages (from requests->unstructured[pdf]) (3.6)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /Users/naesalang/miniconda3/envs/openai/lib/python3.12/site-packages (from requests->unstructured[pdf]) (2.2.1)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /Users/naesalang/miniconda3/envs/openai/lib/python3.12/site-packages (from requests->unstructured[pdf]) (2024.2.2)\n",
      "Collecting cffi>=1.12 (from cryptography>=36.0.0->pdfminer.six->unstructured[pdf])\n",
      "  Downloading cffi-1.16.0-cp312-cp312-macosx_10_9_x86_64.whl.metadata (1.5 kB)\n",
      "Requirement already satisfied: mypy-extensions>=0.3.0 in /Users/naesalang/miniconda3/envs/openai/lib/python3.12/site-packages (from typing-inspect<1,>=0.4.0->dataclasses-json->unstructured[pdf]) (1.0.0)\n",
      "Requirement already satisfied: pydantic!=1.8,!=1.8.1,!=2.0.0,!=2.0.1,!=2.1.0,<3.0.0,>=1.7.4 in /Users/naesalang/miniconda3/envs/openai/lib/python3.12/site-packages (from fastapi->unstructured-inference->unstructured[pdf]) (2.6.3)\n",
      "Collecting starlette<0.37.0,>=0.36.3 (from fastapi->unstructured-inference->unstructured[pdf])\n",
      "  Using cached starlette-0.36.3-py3-none-any.whl.metadata (5.9 kB)\n",
      "Collecting filelock (from huggingface-hub->unstructured-inference==0.7.18->unstructured[pdf])\n",
      "  Downloading filelock-3.13.1-py3-none-any.whl.metadata (2.8 kB)\n",
      "Collecting fsspec>=2023.5.0 (from huggingface-hub->unstructured-inference==0.7.18->unstructured[pdf])\n",
      "  Downloading fsspec-2024.2.0-py3-none-any.whl.metadata (6.8 kB)\n",
      "Requirement already satisfied: pyyaml>=5.1 in /Users/naesalang/miniconda3/envs/openai/lib/python3.12/site-packages (from huggingface-hub->unstructured-inference==0.7.18->unstructured[pdf]) (6.0.1)\n",
      "Collecting scipy (from layoutparser[layoutmodels,tesseract]->unstructured-inference==0.7.18->unstructured[pdf])\n",
      "  Downloading scipy-1.12.0-cp312-cp312-macosx_10_9_x86_64.whl.metadata (60 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m60.4/60.4 kB\u001b[0m \u001b[31m4.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: pandas in /Users/naesalang/miniconda3/envs/openai/lib/python3.12/site-packages (from layoutparser[layoutmodels,tesseract]->unstructured-inference==0.7.18->unstructured[pdf]) (2.2.1)\n",
      "Collecting iopath (from layoutparser[layoutmodels,tesseract]->unstructured-inference==0.7.18->unstructured[pdf])\n",
      "  Downloading iopath-0.1.10.tar.gz (42 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m42.2/42.2 kB\u001b[0m \u001b[31m3.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25hCollecting pdfplumber (from layoutparser[layoutmodels,tesseract]->unstructured-inference==0.7.18->unstructured[pdf])\n",
      "  Downloading pdfplumber-0.10.4-py3-none-any.whl.metadata (39 kB)\n",
      "Collecting torch (from layoutparser[layoutmodels,tesseract]->unstructured-inference==0.7.18->unstructured[pdf])\n",
      "  Downloading torch-2.2.1-cp312-none-macosx_10_9_x86_64.whl.metadata (25 kB)\n",
      "Collecting torchvision (from layoutparser[layoutmodels,tesseract]->unstructured-inference==0.7.18->unstructured[pdf])\n",
      "  Downloading torchvision-0.17.1-cp312-cp312-macosx_10_13_x86_64.whl.metadata (6.6 kB)\n",
      "Collecting effdet (from layoutparser[layoutmodels,tesseract]->unstructured-inference==0.7.18->unstructured[pdf])\n",
      "  Downloading effdet-0.4.1-py3-none-any.whl.metadata (33 kB)\n",
      "Collecting pytesseract (from layoutparser[layoutmodels,tesseract]->unstructured-inference==0.7.18->unstructured[pdf])\n",
      "  Downloading pytesseract-0.3.10-py3-none-any.whl.metadata (11 kB)\n",
      "Requirement already satisfied: h11>=0.8 in /Users/naesalang/miniconda3/envs/openai/lib/python3.12/site-packages (from uvicorn->unstructured-inference->unstructured[pdf]) (0.14.0)\n",
      "Collecting pycparser (from cffi>=1.12->cryptography>=36.0.0->pdfminer.six->unstructured[pdf])\n",
      "  Downloading pycparser-2.21-py2.py3-none-any.whl.metadata (1.1 kB)\n",
      "Requirement already satisfied: annotated-types>=0.4.0 in /Users/naesalang/miniconda3/envs/openai/lib/python3.12/site-packages (from pydantic!=1.8,!=1.8.1,!=2.0.0,!=2.0.1,!=2.1.0,<3.0.0,>=1.7.4->fastapi->unstructured-inference->unstructured[pdf]) (0.6.0)\n",
      "Requirement already satisfied: pydantic-core==2.16.3 in /Users/naesalang/miniconda3/envs/openai/lib/python3.12/site-packages (from pydantic!=1.8,!=1.8.1,!=2.0.0,!=2.0.1,!=2.1.0,<3.0.0,>=1.7.4->fastapi->unstructured-inference->unstructured[pdf]) (2.16.3)\n",
      "Requirement already satisfied: anyio<5,>=3.4.0 in /Users/naesalang/miniconda3/envs/openai/lib/python3.12/site-packages (from starlette<0.37.0,>=0.36.3->fastapi->unstructured-inference->unstructured[pdf]) (4.3.0)\n",
      "Collecting timm>=0.9.2 (from effdet->layoutparser[layoutmodels,tesseract]->unstructured-inference==0.7.18->unstructured[pdf])\n",
      "  Downloading timm-0.9.16-py3-none-any.whl.metadata (38 kB)\n",
      "Collecting pycocotools>=2.0.2 (from effdet->layoutparser[layoutmodels,tesseract]->unstructured-inference==0.7.18->unstructured[pdf])\n",
      "  Downloading pycocotools-2.0.7.tar.gz (24 kB)\n",
      "  Installing build dependencies ... \u001b[?25ldone\n",
      "\u001b[?25h  Getting requirements to build wheel ... \u001b[?25ldone\n",
      "\u001b[?25h  Preparing metadata (pyproject.toml) ... \u001b[?25ldone\n",
      "\u001b[?25hCollecting omegaconf>=2.0 (from effdet->layoutparser[layoutmodels,tesseract]->unstructured-inference==0.7.18->unstructured[pdf])\n",
      "  Downloading omegaconf-2.3.0-py3-none-any.whl.metadata (3.9 kB)\n",
      "Collecting sympy (from torch->layoutparser[layoutmodels,tesseract]->unstructured-inference==0.7.18->unstructured[pdf])\n",
      "  Downloading sympy-1.12-py3-none-any.whl.metadata (12 kB)\n",
      "Collecting networkx (from torch->layoutparser[layoutmodels,tesseract]->unstructured-inference==0.7.18->unstructured[pdf])\n",
      "  Downloading networkx-3.2.1-py3-none-any.whl.metadata (5.2 kB)\n",
      "Collecting jinja2 (from torch->layoutparser[layoutmodels,tesseract]->unstructured-inference==0.7.18->unstructured[pdf])\n",
      "  Downloading Jinja2-3.1.3-py3-none-any.whl.metadata (3.3 kB)\n",
      "Collecting portalocker (from iopath->layoutparser[layoutmodels,tesseract]->unstructured-inference==0.7.18->unstructured[pdf])\n",
      "  Downloading portalocker-2.8.2-py3-none-any.whl.metadata (8.5 kB)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in /Users/naesalang/miniconda3/envs/openai/lib/python3.12/site-packages (from pandas->layoutparser[layoutmodels,tesseract]->unstructured-inference==0.7.18->unstructured[pdf]) (2.8.2)\n",
      "Requirement already satisfied: pytz>=2020.1 in /Users/naesalang/miniconda3/envs/openai/lib/python3.12/site-packages (from pandas->layoutparser[layoutmodels,tesseract]->unstructured-inference==0.7.18->unstructured[pdf]) (2024.1)\n",
      "Requirement already satisfied: tzdata>=2022.7 in /Users/naesalang/miniconda3/envs/openai/lib/python3.12/site-packages (from pandas->layoutparser[layoutmodels,tesseract]->unstructured-inference==0.7.18->unstructured[pdf]) (2024.1)\n",
      "Collecting pdfminer.six (from unstructured[pdf])\n",
      "  Downloading pdfminer.six-20221105-py3-none-any.whl.metadata (4.0 kB)\n",
      "Collecting pypdfium2>=4.18.0 (from pdfplumber->layoutparser[layoutmodels,tesseract]->unstructured-inference==0.7.18->unstructured[pdf])\n",
      "  Downloading pypdfium2-4.27.0-py3-none-macosx_10_13_x86_64.whl.metadata (48 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m48.1/48.1 kB\u001b[0m \u001b[31m3.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: sniffio>=1.1 in /Users/naesalang/miniconda3/envs/openai/lib/python3.12/site-packages (from anyio<5,>=3.4.0->starlette<0.37.0,>=0.36.3->fastapi->unstructured-inference->unstructured[pdf]) (1.3.1)\n",
      "Collecting antlr4-python3-runtime==4.9.* (from omegaconf>=2.0->effdet->layoutparser[layoutmodels,tesseract]->unstructured-inference==0.7.18->unstructured[pdf])\n",
      "  Downloading antlr4-python3-runtime-4.9.3.tar.gz (117 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m117.0/117.0 kB\u001b[0m \u001b[31m8.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25hCollecting matplotlib>=2.1.0 (from pycocotools>=2.0.2->effdet->layoutparser[layoutmodels,tesseract]->unstructured-inference==0.7.18->unstructured[pdf])\n",
      "  Downloading matplotlib-3.8.3-cp312-cp312-macosx_10_12_x86_64.whl.metadata (5.8 kB)\n",
      "Requirement already satisfied: six>=1.5 in /Users/naesalang/miniconda3/envs/openai/lib/python3.12/site-packages (from python-dateutil>=2.8.2->pandas->layoutparser[layoutmodels,tesseract]->unstructured-inference==0.7.18->unstructured[pdf]) (1.16.0)\n",
      "Collecting safetensors (from timm>=0.9.2->effdet->layoutparser[layoutmodels,tesseract]->unstructured-inference==0.7.18->unstructured[pdf])\n",
      "  Downloading safetensors-0.4.2-cp312-cp312-macosx_10_12_x86_64.whl.metadata (3.8 kB)\n",
      "Collecting MarkupSafe>=2.0 (from jinja2->torch->layoutparser[layoutmodels,tesseract]->unstructured-inference==0.7.18->unstructured[pdf])\n",
      "  Downloading MarkupSafe-2.1.5-cp312-cp312-macosx_10_9_x86_64.whl.metadata (3.0 kB)\n",
      "Collecting mpmath>=0.19 (from sympy->torch->layoutparser[layoutmodels,tesseract]->unstructured-inference==0.7.18->unstructured[pdf])\n",
      "  Downloading mpmath-1.3.0-py3-none-any.whl.metadata (8.6 kB)\n",
      "Collecting contourpy>=1.0.1 (from matplotlib>=2.1.0->pycocotools>=2.0.2->effdet->layoutparser[layoutmodels,tesseract]->unstructured-inference==0.7.18->unstructured[pdf])\n",
      "  Downloading contourpy-1.2.0-cp312-cp312-macosx_10_9_x86_64.whl.metadata (5.8 kB)\n",
      "Collecting cycler>=0.10 (from matplotlib>=2.1.0->pycocotools>=2.0.2->effdet->layoutparser[layoutmodels,tesseract]->unstructured-inference==0.7.18->unstructured[pdf])\n",
      "  Downloading cycler-0.12.1-py3-none-any.whl.metadata (3.8 kB)\n",
      "Collecting fonttools>=4.22.0 (from matplotlib>=2.1.0->pycocotools>=2.0.2->effdet->layoutparser[layoutmodels,tesseract]->unstructured-inference==0.7.18->unstructured[pdf])\n",
      "  Downloading fonttools-4.49.0-cp312-cp312-macosx_10_9_x86_64.whl.metadata (159 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m159.1/159.1 kB\u001b[0m \u001b[31m13.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hCollecting kiwisolver>=1.3.1 (from matplotlib>=2.1.0->pycocotools>=2.0.2->effdet->layoutparser[layoutmodels,tesseract]->unstructured-inference==0.7.18->unstructured[pdf])\n",
      "  Downloading kiwisolver-1.4.5-cp312-cp312-macosx_10_9_x86_64.whl.metadata (6.4 kB)\n",
      "Collecting pyparsing>=2.3.1 (from matplotlib>=2.1.0->pycocotools>=2.0.2->effdet->layoutparser[layoutmodels,tesseract]->unstructured-inference==0.7.18->unstructured[pdf])\n",
      "  Downloading pyparsing-3.1.1-py3-none-any.whl.metadata (5.1 kB)\n",
      "Downloading opencv_python-4.6.0.66-cp36-abi3-macosx_10_15_x86_64.whl (46.4 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m46.4/46.4 MB\u001b[0m \u001b[31m3.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hDownloading unstructured.pytesseract-0.3.12-py3-none-any.whl (14 kB)\n",
      "Downloading beautifulsoup4-4.12.3-py3-none-any.whl (147 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m147.9/147.9 kB\u001b[0m \u001b[31m10.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading chardet-5.2.0-py3-none-any.whl (199 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m199.4/199.4 kB\u001b[0m \u001b[31m16.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading emoji-2.10.1-py2.py3-none-any.whl (421 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m421.5/421.5 kB\u001b[0m \u001b[31m2.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hDownloading filetype-1.2.0-py2.py3-none-any.whl (19 kB)\n",
      "Downloading lxml-5.1.0-cp312-cp312-macosx_10_9_x86_64.whl (4.8 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m4.8/4.8 MB\u001b[0m \u001b[31m2.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hDownloading nltk-3.8.1-py3-none-any.whl (1.5 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.5/1.5 MB\u001b[0m \u001b[31m2.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0mm\n",
      "\u001b[?25hDownloading pdf2image-1.17.0-py3-none-any.whl (11 kB)\n",
      "Downloading python_iso639-2024.2.7-py3-none-any.whl (274 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m274.7/274.7 kB\u001b[0m \u001b[31m3.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hDownloading python_magic-0.4.27-py2.py3-none-any.whl (13 kB)\n",
      "Downloading tabulate-0.9.0-py3-none-any.whl (35 kB)\n",
      "Downloading unstructured-0.10.16-py3-none-any.whl (1.5 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.5/1.5 MB\u001b[0m \u001b[31m2.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0mm\n",
      "\u001b[?25hDownloading cryptography-42.0.5-cp39-abi3-macosx_10_12_universal2.whl (5.9 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m5.9/5.9 MB\u001b[0m \u001b[31m2.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hDownloading pillow-10.2.0-cp312-cp312-macosx_10_10_x86_64.whl (3.5 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.5/3.5 MB\u001b[0m \u001b[31m2.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hDownloading soupsieve-2.5-py3-none-any.whl (36 kB)\n",
      "Using cached click-8.1.7-py3-none-any.whl (97 kB)\n",
      "Using cached fastapi-0.110.0-py3-none-any.whl (92 kB)\n",
      "Downloading huggingface_hub-0.21.2-py3-none-any.whl (346 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m346.2/346.2 kB\u001b[0m \u001b[31m17.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading joblib-1.3.2-py3-none-any.whl (302 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m302.2/302.2 kB\u001b[0m \u001b[31m15.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading python_multipart-0.0.9-py3-none-any.whl (22 kB)\n",
      "Downloading uvicorn-0.27.1-py3-none-any.whl (60 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m60.8/60.8 kB\u001b[0m \u001b[31m5.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading cffi-1.16.0-cp312-cp312-macosx_10_9_x86_64.whl (183 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m183.3/183.3 kB\u001b[0m \u001b[31m14.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading fsspec-2024.2.0-py3-none-any.whl (170 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m170.9/170.9 kB\u001b[0m \u001b[31m2.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hUsing cached starlette-0.36.3-py3-none-any.whl (71 kB)\n",
      "Downloading effdet-0.4.1-py3-none-any.whl (112 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m112.5/112.5 kB\u001b[0m \u001b[31m3.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading torch-2.2.1-cp312-none-macosx_10_9_x86_64.whl (150.8 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m150.8/150.8 MB\u001b[0m \u001b[31m3.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hDownloading filelock-3.13.1-py3-none-any.whl (11 kB)\n",
      "Downloading layoutparser-0.3.4-py3-none-any.whl (19.2 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m19.2/19.2 MB\u001b[0m \u001b[31m4.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hDownloading pdfplumber-0.10.4-py3-none-any.whl (54 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m54.7/54.7 kB\u001b[0m \u001b[31m2.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading pdfminer.six-20221105-py3-none-any.whl (5.6 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m5.6/5.6 MB\u001b[0m \u001b[31m4.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hDownloading pytesseract-0.3.10-py3-none-any.whl (14 kB)\n",
      "Downloading scipy-1.12.0-cp312-cp312-macosx_10_9_x86_64.whl (38.9 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m38.9/38.9 MB\u001b[0m \u001b[31m3.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hDownloading torchvision-0.17.1-cp312-cp312-macosx_10_13_x86_64.whl (1.7 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.7/1.7 MB\u001b[0m \u001b[31m3.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hDownloading omegaconf-2.3.0-py3-none-any.whl (79 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m79.5/79.5 kB\u001b[0m \u001b[31m7.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading pypdfium2-4.27.0-py3-none-macosx_10_13_x86_64.whl (2.9 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.9/2.9 MB\u001b[0m \u001b[31m3.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0mm\n",
      "\u001b[?25hDownloading timm-0.9.16-py3-none-any.whl (2.2 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.2/2.2 MB\u001b[0m \u001b[31m3.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hDownloading Jinja2-3.1.3-py3-none-any.whl (133 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m133.2/133.2 kB\u001b[0m \u001b[31m3.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading networkx-3.2.1-py3-none-any.whl (1.6 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.6/1.6 MB\u001b[0m \u001b[31m3.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hDownloading portalocker-2.8.2-py3-none-any.whl (17 kB)\n",
      "Downloading pycparser-2.21-py2.py3-none-any.whl (118 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m118.7/118.7 kB\u001b[0m \u001b[31m10.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading sympy-1.12-py3-none-any.whl (5.7 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m5.7/5.7 MB\u001b[0m \u001b[31m3.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hDownloading MarkupSafe-2.1.5-cp312-cp312-macosx_10_9_x86_64.whl (14 kB)\n",
      "Downloading matplotlib-3.8.3-cp312-cp312-macosx_10_12_x86_64.whl (7.6 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m7.6/7.6 MB\u001b[0m \u001b[31m3.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hDownloading mpmath-1.3.0-py3-none-any.whl (536 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m536.2/536.2 kB\u001b[0m \u001b[31m4.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hDownloading safetensors-0.4.2-cp312-cp312-macosx_10_12_x86_64.whl (425 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m425.7/425.7 kB\u001b[0m \u001b[31m6.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hDownloading contourpy-1.2.0-cp312-cp312-macosx_10_9_x86_64.whl (259 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m259.3/259.3 kB\u001b[0m \u001b[31m3.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hDownloading cycler-0.12.1-py3-none-any.whl (8.3 kB)\n",
      "Downloading fonttools-4.49.0-cp312-cp312-macosx_10_9_x86_64.whl (2.3 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.3/2.3 MB\u001b[0m \u001b[31m3.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0mm\n",
      "\u001b[?25hDownloading kiwisolver-1.4.5-cp312-cp312-macosx_10_9_x86_64.whl (67 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m67.3/67.3 kB\u001b[0m \u001b[31m5.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading pyparsing-3.1.1-py3-none-any.whl (103 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m103.1/103.1 kB\u001b[0m \u001b[31m8.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hBuilding wheels for collected packages: unstructured-inference, iopath, antlr4-python3-runtime, pycocotools\n",
      "  Building wheel for unstructured-inference (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25h  Created wheel for unstructured-inference: filename=unstructured_inference-0.2.4-py3-none-any.whl size=10089 sha256=e688d3ed1b239b71afa493d41b55af975fb6b6403d69d74c41767f03991560db\n",
      "  Stored in directory: /Users/naesalang/Library/Caches/pip/wheels/53/fc/71/8145ee906e71c499062c98a3ab60a856dbc3f988486469d746\n",
      "  Building wheel for iopath (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25h  Created wheel for iopath: filename=iopath-0.1.10-py3-none-any.whl size=31530 sha256=418b3e52c34a0815e59ae7ad30ceaab099df5de4d5edcd7a62b4f42e81df10db\n",
      "  Stored in directory: /Users/naesalang/Library/Caches/pip/wheels/7c/96/04/4f5f31ff812f684f69f40cb1634357812220aac58d4698048c\n",
      "  Building wheel for antlr4-python3-runtime (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25h  Created wheel for antlr4-python3-runtime: filename=antlr4_python3_runtime-4.9.3-py3-none-any.whl size=144554 sha256=861600fa2c01da774d81296f5978f80a1e548a52bb11b99e493e1237b028985d\n",
      "  Stored in directory: /Users/naesalang/Library/Caches/pip/wheels/1f/be/48/13754633f1d08d1fbfc60d5e80ae1e5d7329500477685286cd\n",
      "  Building wheel for pycocotools (pyproject.toml) ... \u001b[?25ldone\n",
      "\u001b[?25h  Created wheel for pycocotools: filename=pycocotools-2.0.7-cp312-cp312-macosx_10_9_x86_64.whl size=86981 sha256=9aeafb32df0568f769d8c7b6d016052d8b193f0f0643d984339c63351e30c110\n",
      "  Stored in directory: /Users/naesalang/Library/Caches/pip/wheels/1e/b8/6d/646852bb348f96f4928351fc4b023cdace78cb8f43d2244ded\n",
      "Successfully built unstructured-inference iopath antlr4-python3-runtime pycocotools\n",
      "Installing collected packages: mpmath, filetype, antlr4-python3-runtime, tabulate, sympy, soupsieve, scipy, safetensors, python-multipart, python-magic, python-iso639, pypdfium2, pyparsing, pycparser, portalocker, Pillow, opencv-python, omegaconf, networkx, MarkupSafe, lxml, kiwisolver, joblib, fsspec, fonttools, filelock, emoji, cycler, contourpy, click, chardet, uvicorn, unstructured.pytesseract, starlette, pytesseract, pdf2image, nltk, matplotlib, jinja2, iopath, huggingface-hub, cffi, beautifulsoup4, unstructured, torch, pycocotools, fastapi, cryptography, torchvision, pdfminer.six, timm, pdfplumber, layoutparser, effdet, unstructured-inference\n",
      "Successfully installed MarkupSafe-2.1.5 Pillow-10.2.0 antlr4-python3-runtime-4.9.3 beautifulsoup4-4.12.3 cffi-1.16.0 chardet-5.2.0 click-8.1.7 contourpy-1.2.0 cryptography-42.0.5 cycler-0.12.1 effdet-0.4.1 emoji-2.10.1 fastapi-0.110.0 filelock-3.13.1 filetype-1.2.0 fonttools-4.49.0 fsspec-2024.2.0 huggingface-hub-0.21.2 iopath-0.1.10 jinja2-3.1.3 joblib-1.3.2 kiwisolver-1.4.5 layoutparser-0.3.4 lxml-5.1.0 matplotlib-3.8.3 mpmath-1.3.0 networkx-3.2.1 nltk-3.8.1 omegaconf-2.3.0 opencv-python-4.6.0.66 pdf2image-1.17.0 pdfminer.six-20221105 pdfplumber-0.10.4 portalocker-2.8.2 pycocotools-2.0.7 pycparser-2.21 pyparsing-3.1.1 pypdfium2-4.27.0 pytesseract-0.3.10 python-iso639-2024.2.7 python-magic-0.4.27 python-multipart-0.0.9 safetensors-0.4.2 scipy-1.12.0 soupsieve-2.5 starlette-0.36.3 sympy-1.12 tabulate-0.9.0 timm-0.9.16 torch-2.2.1 torchvision-0.17.1 unstructured-0.10.16 unstructured-inference-0.2.4 unstructured.pytesseract-0.3.12 uvicorn-0.27.1\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install \"unstructured[pdf]\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "5d60a17f-f40e-4d8d-aeca-8b8d44053bb9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Andrey Maximov Full-Stack Developer\n",
      "\n",
      "amaximov.off@gmail.com\n",
      "\n",
      "+7916793111\n",
      "\n",
      "PROJECTS\n",
      "\n",
      "Microservice Application Python, Apache Kafka, Zookeeper, KafkaConnector, Docker, Postgresql, MongoDB, Elasticsearch 02/2023 – 03/2023 Creating a microservice application using Apache Kafka to update the information between databases.\n",
      "\n",
      "PROFILE\n",
      "\n",
      "Full-stack developer adept in working in both front-end and backend development processes with 3 year of experience in Python, Django in REST, JS, React, SQL. Well versed and programming implementation of functional specifications. Knowledge of different programming languages and various development tools and frameworks.\n",
      "\n",
      "design,\n",
      "\n",
      "development,\n",
      "\n",
      "Development of a Secure Smart Home Management Service JavaScript, React, Mobx, Docker, CI/CD 09/2022 – 06/2023 Development of client's part of security service and automation of smart home management processes using JS React. The system has a dynamic smart home design module which was developed using library Mobx and Canvas component.\n",
      "\n",
      "SKILLS\n",
      "\n",
      "Python Django REST, FastAPI, Celery, libraries (pdfkit, xlsxwriter, datetime, etc)\n",
      "\n",
      "NodeJS React, MobX, Redux, Math, Canvas\n",
      "\n",
      "SQL PostgreSQL, MySQL\n",
      "\n",
      "Git version control\n",
      "\n",
      "Docker\n",
      "\n",
      "Parser for data collection Python (selenium, browsermobproxy, json, requests) 08/2023 – 08/2023 The parser for collecting data from a website using a proxy server and API requests.\n",
      "\n",
      "Development of a Graphical Application Using the MVC Pattern QT, SQL 09/2022 – 11/2022 A graphical application that writes/reads data from a database entity to/from a local file on a computer.\n",
      "\n",
      "CI/CD pipelines\n",
      "\n",
      "HTML & CSS\n",
      "\n",
      "Agile methodologies\n",
      "\n",
      "Security and data protection\n",
      "\n",
      "Development of a Client-Server Application with Database Design and Creation QT, SQL 01/2022 – 05/2022 The client-server application that works with SQL server. The software part was developed in QT. The client can add, edit and delete records. A relational database was designed and created.\n",
      "\n",
      "Troubleshooting and debugging\n",
      "\n",
      "French Numbers Parser Python (re library) 12/2022 – 01/2023 A software that converts numbers written in French in cursive into Roman numerals.\n",
      "\n",
      "Team collaboration and communication\n",
      "\n",
      "EDUCATION\n",
      "\n",
      "PROFESSIONAL EXPERIENCE\n",
      "\n",
      "Full-Stack Developer Information Technology Center 08/2022 – present | Moscow, Russia Created 10+ API modules Developed 50+ different React components Provided interaction of a client and server\n",
      "\n",
      "components Code review Worked directly with the database Configured Docker and CI/CD (Python Django REST, JavaScript React, SQL, Docker, CI/CD)\n",
      "\n",
      "Bachelor of Technology - BTech / Information Systems and Technologies MIREA (Russian Technological University) Thesis: Development of a Secure Smart Home Management Service\n",
      "\n",
      "LANGUAGES\n",
      "\n",
      "English\n",
      "\n",
      "Russian\n"
     ]
    }
   ],
   "source": [
    "from unstructured.partition.auto import partition\n",
    "\n",
    "elements = partition(filename=\"Резюме для 1 кейса Хакатона/Andrey Maximov.pdf\")\n",
    "result = \"\\n\\n\".join([str(el) for el in elements])\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c93e899e-8ef2-46af-82f3-8761e83043f6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "gpt-3.5-turbo\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'first_name': 'Andrey',\n",
       " 'last_name': 'Maximov',\n",
       " 'middle_name': '',\n",
       " 'birth_date': '',\n",
       " 'birth_date_year_only': False,\n",
       " 'country': 'Russia',\n",
       " 'city': 'Moscow',\n",
       " 'about': 'Full-stack developer adept in working in both front-end and backend development processes with 3 year of experience in Python, Django in REST, JS, React, SQL. Well versed and programming implementation of functional specifications. Knowledge of different programming languages and various development tools and frameworks.',\n",
       " 'key_skills': 'Python Django REST, FastAPI, Celery, libraries (pdfkit, xlsxwriter, datetime, etc), NodeJS React, MobX, Redux, Math, Canvas, SQL PostgreSQL, MySQL, Git version control, Docker, Parser for data collection Python (selenium, browsermobproxy, json, requests), CI/CD pipelines, HTML & CSS, Agile methodologies, Security and data protection',\n",
       " 'salary_expectations_amount': '',\n",
       " 'salary_expectations_currency': '',\n",
       " 'photo_path': '',\n",
       " 'gender': 'Мужской',\n",
       " 'resume_name': '',\n",
       " 'source_link': '',\n",
       " 'contact': [{'value': 'amaximov.off@gmail.com',\n",
       "   'comment': '',\n",
       "   'contact_type': 'Email'},\n",
       "  {'value': '+7916793111', 'comment': '', 'contact_type': 'Телефон'}],\n",
       " 'education': [{'year': '',\n",
       "   'organization': 'MIREA (Russian Technological University)',\n",
       "   'faculty': '',\n",
       "   'specialty': 'Information Systems and Technologies',\n",
       "   'result': '',\n",
       "   'education_type': '',\n",
       "   'education_level': 'Высшее, Бакалавр'}],\n",
       " 'experience': [{'starts': '08/2022',\n",
       "   'ends': 'present',\n",
       "   'employer': 'Information Technology Center',\n",
       "   'city': 'Moscow',\n",
       "   'url': '',\n",
       "   'position': 'Full-Stack Developer',\n",
       "   'description': 'Created 10+ API modules Developed 50+ different React components Provided interaction of a client and server components Code review Worked directly with the database Configured Docker and CI/CD (Python Django REST, JavaScript React, SQL, Docker, CI/CD)',\n",
       "   'order': '1'}],\n",
       " 'language': [{'language': 'English', 'language_level': ''},\n",
       "  {'language': 'Russian', 'language_level': ''}]}"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from parser import get_json\n",
    "get_json(result, api_key=\"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\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "70fd163b-1fdc-4ce0-8290-7072c4cd67b3",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "openai",
   "language": "python",
   "name": "openai"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
